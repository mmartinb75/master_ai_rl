{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "713d6669",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install stable-baselines3[extra]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab44baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gymnasium[classic-control] in /Users/mmartin/opt/anaconda3/envs/rl_course/lib/python3.12/site-packages (1.1.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /Users/mmartin/opt/anaconda3/envs/rl_course/lib/python3.12/site-packages (from gymnasium[classic-control]) (2.1.3)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /Users/mmartin/opt/anaconda3/envs/rl_course/lib/python3.12/site-packages (from gymnasium[classic-control]) (3.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /Users/mmartin/opt/anaconda3/envs/rl_course/lib/python3.12/site-packages (from gymnasium[classic-control]) (4.12.2)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /Users/mmartin/opt/anaconda3/envs/rl_course/lib/python3.12/site-packages (from gymnasium[classic-control]) (0.0.4)\n",
      "Requirement already satisfied: pygame>=2.1.3 in /Users/mmartin/opt/anaconda3/envs/rl_course/lib/python3.12/site-packages (from gymnasium[classic-control]) (2.6.1)\n"
     ]
    }
   ],
   "source": [
    "#!pip install gymnasium[classic-control]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a237e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f07c244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timesteps taken: 50\n",
      "Total Reward: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1.- Vamos a ejecutar una estrategia con acciones escogidas al azar.\n",
    "#env.s = 328  # set environment to illustration's state\n",
    "import time\n",
    "epochs = 0\n",
    "penalties, reward = 0, 0\n",
    "G = 0\n",
    "frames = [] # for animation\n",
    "done = False\n",
    "observation, info = env.reset(seed=42)\n",
    "#while not done:\n",
    "for i in range(50):\n",
    "\n",
    "    frame = env.render()\n",
    "\n",
    "    # Show frame inline in Jupyter\n",
    "    plt.imshow(frame)\n",
    "    plt.axis(\"off\")\n",
    "    display(plt.gcf())              # Show current figure\n",
    "    clear_output(wait=True)        # Clear previous output\n",
    "    action = env.action_space.sample() # muestreamos una acción al azar\n",
    "    state, reward, done, truncated,info = env.step(action) # ejecutamos dicha acción en nuestro entorno.\n",
    "    \n",
    "    G += reward\n",
    "    epochs += 1\n",
    "\n",
    "    \n",
    "print(\"Timesteps taken: {}\".format(epochs))\n",
    "print(\"Total Reward: {}\".format(penalties))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3999f033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 25.7     |\n",
      "|    ep_rew_mean     | 25.7     |\n",
      "| time/              |          |\n",
      "|    fps             | 5567     |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 27          |\n",
      "|    ep_rew_mean          | 27          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 3221        |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 1           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007944772 |\n",
      "|    clip_fraction        | 0.0958      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.686      |\n",
      "|    explained_variance   | 0.00111     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 9.54        |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0164     |\n",
      "|    value_loss           | 61.9        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 34.1        |\n",
      "|    ep_rew_mean          | 34.1        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2848        |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010122565 |\n",
      "|    clip_fraction        | 0.0715      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.664      |\n",
      "|    explained_variance   | 0.102       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 12.6        |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0178     |\n",
      "|    value_loss           | 34.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 44.2        |\n",
      "|    ep_rew_mean          | 44.2        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2680        |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 3           |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008217018 |\n",
      "|    clip_fraction        | 0.0831      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.636      |\n",
      "|    explained_variance   | 0.192       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 22.3        |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0201     |\n",
      "|    value_loss           | 51.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 55.3        |\n",
      "|    ep_rew_mean          | 55.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2587        |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 3           |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007163597 |\n",
      "|    clip_fraction        | 0.094       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.599      |\n",
      "|    explained_variance   | 0.292       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 26.3        |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0214     |\n",
      "|    value_loss           | 65.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 71.3        |\n",
      "|    ep_rew_mean          | 71.3        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2535        |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 4           |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007288097 |\n",
      "|    clip_fraction        | 0.0651      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.586      |\n",
      "|    explained_variance   | 0.254       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 26.7        |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    value_loss           | 73.6        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 88           |\n",
      "|    ep_rew_mean          | 88           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2504         |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 5            |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0047526695 |\n",
      "|    clip_fraction        | 0.0209       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.583       |\n",
      "|    explained_variance   | 0.451        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 18.8         |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.00557     |\n",
      "|    value_loss           | 54.1         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 103          |\n",
      "|    ep_rew_mean          | 103          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2466         |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 6            |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0049145333 |\n",
      "|    clip_fraction        | 0.0472       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.58        |\n",
      "|    explained_variance   | 0.788        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 4.02         |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.00647     |\n",
      "|    value_loss           | 32.9         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 120          |\n",
      "|    ep_rew_mean          | 120          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2455         |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 7            |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0053418446 |\n",
      "|    clip_fraction        | 0.0616       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.582       |\n",
      "|    explained_variance   | 0.702        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 27           |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.0103      |\n",
      "|    value_loss           | 42.6         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 136         |\n",
      "|    ep_rew_mean          | 136         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2449        |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009666154 |\n",
      "|    clip_fraction        | 0.124       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.57       |\n",
      "|    explained_variance   | 0.745       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 4.63        |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0125     |\n",
      "|    value_loss           | 53.4        |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 152          |\n",
      "|    ep_rew_mean          | 152          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 2442         |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 9            |\n",
      "|    total_timesteps      | 22528        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0032499083 |\n",
      "|    clip_fraction        | 0.00957      |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.581       |\n",
      "|    explained_variance   | 0.936        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.71         |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.00199     |\n",
      "|    value_loss           | 15.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 171         |\n",
      "|    ep_rew_mean          | 171         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 2435        |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009943614 |\n",
      "|    clip_fraction        | 0.129       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.557      |\n",
      "|    explained_variance   | 0.915       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 14.5        |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0168     |\n",
      "|    value_loss           | 24.3        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 189        |\n",
      "|    ep_rew_mean          | 189        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 2424       |\n",
      "|    iterations           | 13         |\n",
      "|    time_elapsed         | 10         |\n",
      "|    total_timesteps      | 26624      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01185799 |\n",
      "|    clip_fraction        | 0.124      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.571     |\n",
      "|    explained_variance   | 0.961      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 2.62       |\n",
      "|    n_updates            | 120        |\n",
      "|    policy_gradient_loss | -0.0157    |\n",
      "|    value_loss           | 9.8        |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x3141b3200>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from stable_baselines3 import PPO\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1)\n",
    "model.learn(total_timesteps=25000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be390a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timesteps taken: 150\n",
      "Total Reward: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import time\n",
    "epochs = 0\n",
    "penalties, reward = 0, 0\n",
    "G = 0\n",
    "frames = [] # for animation\n",
    "done = False\n",
    "observation, info = env.reset(seed=42)\n",
    "#while not done:\n",
    "for i in range(150):\n",
    "\n",
    "    frame = env.render()\n",
    "\n",
    "    # Show frame inline in Jupyter\n",
    "    plt.imshow(frame)\n",
    "    plt.axis(\"off\")\n",
    "    display(plt.gcf())              # Show current figure\n",
    "    clear_output(wait=True)        # Clear previous output\n",
    "    action, _states = model.predict(state)\n",
    "    state, reward, done, truncated,info = env.step(action) # ejecutamos dicha acción en nuestro entorno.\n",
    "    \n",
    "    G += reward\n",
    "    epochs += 1\n",
    "\n",
    "    \n",
    "print(\"Timesteps taken: {}\".format(epochs))\n",
    "print(\"Total Reward: {}\".format(penalties))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl_course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
